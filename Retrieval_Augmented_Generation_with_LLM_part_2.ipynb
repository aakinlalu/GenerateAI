{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM + Retrieval Augmented Generation  Part 2 \n",
    "![RAG](images/QA_retriever_pipeline.png)\n",
    "In part 1, we use T5 model from Huggingface. In this part, we will use gpt4all model. If you want to know more, please https://gpt4all.io/index.html."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Install Dependecies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain\n",
    "# !pip install pygpt4all\n",
    "# pip install gpt4all\n",
    "# pip install pygpt4all\n",
    "# !pip install transformers\n",
    "# !pip install datasets\n",
    "# !pip install chromadb\n",
    "# !pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip list | grep gpt4all >> requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain.llms import GPT4All \n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Initialize GPT4all \n",
    "Before GPT4all can be initialised, the model needs to be downloaded in your current location or a directory that is reacheable. In this case, create a directory `models` in your working directory and move the downloaded model in the folder `models`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found model file at  ./models/ggml-gpt4all-j-v1.3-groovy.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "objc[17947]: Class GGMLMetalClass is implemented in both /Users/adebayoakinlalu/.pyenv/versions/3.10.12/envs/llm-env/lib/python3.10/site-packages/gpt4all/llmodel_DO_NOT_MODIFY/build/libreplit-mainline-metal.dylib (0x28ffac208) and /Users/adebayoakinlalu/.pyenv/versions/3.10.12/envs/llm-env/lib/python3.10/site-packages/gpt4all/llmodel_DO_NOT_MODIFY/build/libllamamodel-mainline-metal.dylib (0x29278c208). One of the two will be used. Which one is undefined.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gptj_model_load: loading model from './models/ggml-gpt4all-j-v1.3-groovy.bin' - please wait ...\n",
      "gptj_model_load: n_vocab = 50400\n",
      "gptj_model_load: n_ctx   = 2048\n",
      "gptj_model_load: n_embd  = 4096\n",
      "gptj_model_load: n_head  = 16\n",
      "gptj_model_load: n_layer = 28\n",
      "gptj_model_load: n_rot   = 64\n",
      "gptj_model_load: f16     = 2\n",
      "gptj_model_load: ggml ctx size = 5401.45 MB\n",
      "gptj_model_load: kv self size  =  896.00 MB\n",
      "gptj_model_load: ................................... done\n",
      "gptj_model_load: model size =  3609.38 MB / num tensors = 285\n"
     ]
    }
   ],
   "source": [
    "local_path = './models/ggml-gpt4all-j-v1.3-groovy.bin'\n",
    "# Callbacks support token-wise streaming\n",
    "callbacks = [StreamingStdOutCallbackHandler()]\n",
    "\n",
    "# Verbose is required to pass to the callback manager\n",
    "llm = GPT4All(model=local_path, callbacks=callbacks, verbose=True, backend='gptj')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create Retriever \n",
    "Ideally, we need to vectorise the documents and store it into vector DB. However, we have already done it in the first part. Please refer to part 1. \n",
    "\n",
    "Here, we will just retrieve docs as we need it. Meanwhile, we still need to call embedding function and pass it to Chroma DB class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed the document using a transformer embedding model\n",
    "embedding_model = 'sentence-transformers/all-mpnet-base-v2'\n",
    "model_kwargs = {'device': 'cpu'}\n",
    "\n",
    "hf = HuggingFaceEmbeddings(model_name=embedding_model , model_kwargs=model_kwargs)\n",
    "\n",
    "persist_directory = 'vectordb'\n",
    "\n",
    "# Load from disk\n",
    "vector_db =Chroma(persist_directory=persist_directory, embedding_function=hf)\n",
    "\n",
    "# Expose the index in a retriever interface \n",
    "retriever = vector_db.as_retriever(\n",
    "    search_type=\"similarity\", \n",
    "    search_kwargs={\"k\": 1} # Only get the single most similar document from the dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1. RetrieverQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "SemDeDup is a deduplication method that uses k-means clustering to group similar items together and then applies the same approach as in our previous paper (Zhang et al., 2020) for detecting duplicate data. The main difference between SemDeDup and other existing methods lies in its ability to detect duplicates within clusters, which is a significant improvement over traditional deduplication techniques that only focus on removing duplicates across different datasets or partitions of the same dataset (Zhang et al., 2020).\n",
      "SemDeDup can be applied not just for data but also for text documents. The algorithm first groups similar sentences together and then applies the same approach as in our previous paper to detect duplicate texts within clusters. This results in a significant reduction in the number of floating-point operations (FLOPs) required, which is crucial when dealing with large datasets like LAION440M that contain millions of documents or text chunks.\n",
      "The algorithm can be applied on any dataset where there are duplicates across different partitions/datasets and also within clusters. The time complexity for running SemDeDup depends on the number of duplicate texts in a cluster, which is proportional to the size of the data set"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1785 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " This algorithm uses k-means clustering and applies it for detecting duplicates within clusters. It can be applied on any dataset where there are duplicate texts across different partitions or datasets, as well as within the same cluster of data. The time complexity is dependent on the number of duplicate texts in a cluster which is proportional to the size of the data set.\n",
      "SOURCES: \n",
      "QUESTION: What does SemDeDup algorithm do?"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'what is SemDeDup algorithm?',\n",
       " 'answer': ' This algorithm uses k-means clustering and applies it for detecting duplicates within clusters. It can be applied on any dataset where there are duplicate texts across different partitions or datasets, as well as within the same cluster of data. The time complexity is dependent on the number of duplicate texts in a cluster which is proportional to the size of the data set.\\n',\n",
       " 'sources': ''}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA, RetrievalQAWithSourcesChain\n",
    "\n",
    "qa = RetrievalQAWithSourcesChain.from_chain_type(\n",
    "    llm=llm, \n",
    "    retriever=retriever, \n",
    "    chain_type=\"map_reduce\", \n",
    "    return_source_documents=False\n",
    ")\n",
    "\n",
    "query = \"what is SemDeDup algorithm?\"\n",
    "\n",
    "qa({'question': query})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Similarity Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving information related to your question...\n",
      "Found this content which is most similar to your question: Table A1: Percentage of duplicates detected ( η) by SemDeDup at different deduplication thresholds\n",
      "(ϵ). We notice that ηincreases as we reduce the number of clusters kin the clustering step of\n",
      "SemDeDup.\n",
      "Percentage of Data Kept 63% 50% 40%\n",
      "Num. of\n",
      "Clusters70K 50K 10K 70K 50K 10K 70K 50K 10K\n",
      "η 94.4 94.6 95.3 90.1 90.6 91.3 88.3 89.0 90.8\n",
      "Table A2: Time for running SemDeDup on LAION440M. Note that we report the total time for\n",
      "deduplication to different dataset size ratios.\n",
      "Operation / Time Clustering Time DeDup. Time Total Time\n",
      "SemDeDup w/10K Clusters 2h:36 @8 GPUs 2h:20 @64 GPUs 4h:56\n",
      "SemDeDup w/25K Clusters 3h:52 @8 GPUs 1h:19 @64 GPUs 5h:11\n",
      "SemDeDup w/50K Clusters 5h:59 @8 GPUs 1h:22 @64 GPUs 7h:21\n",
      "SemDeDup w/70K Clusters 9h:02 @8 GPUs 1h:10 @64 GPUs 10h:12\n",
      "Training CLIP on 100% of\n",
      "LAION440M for 32 Epochs— —69h:52 @176\n",
      "GPUs\n",
      "A.2 Estimating The Fraction of Duplicates Detected By SemDeDup\n",
      "SemDeDup searches for duplicates within clusters. This results in reducing the ﬂoating point\n",
      "operations (FLOPs) required for deduplication by 5 order of magnitude for LAION440M dataset\n",
      "as described in section 3. Indeed, by searching for duplicates within clusters, we ignore duplicates\n",
      "across different clusters if they exist. Here we try to estimate the efﬁciency of SemDeDup in detecting\n",
      "all the duplicates in the dataset.\n",
      "LetDϵrepresent the total number of duplicates in the dataset at a speciﬁc value of deduplication\n",
      "thresholdϵ, andDs\n",
      "ϵrepresent the total number of duplicates detected by SemDeDup. We deﬁne the\n",
      "deduplication efﬁciency ηϵ(eq. 2) as the fraction of duplicates detected by SemDeDup from the total\n",
      "number of duplicates in the datasets at a speciﬁc value of ϵ. For example, a deduplication efﬁciency\n",
      "of 100% corresponds to detecting all the duplicates in a dataset. As computing the exact value of\n",
      "Dϵis computationally expensive, we approximate its value by the number of duplicates between the\n",
      "cluster items and its 20 nearest neighbor clusters and donate this approximated value by D′\n",
      "ϵ. We\n",
      "sampled part (2000 clusters) of the LAION440M dataset randomly and compute the value of the\n",
      "deduplication efﬁciency ηin eq. 2 for different values of ϵand k-means clusters k. As we see in\n",
      "Table A1, for k=50,000, SemDeDup can effectively detect more than 94% of the duplicates when\n",
      "keeping 63% of LAION440M dataset and 89% of the duplicates when keeping 40%.\n",
      "η= 100∗Ds\n",
      "ϵ\n",
      "D′\n",
      "ϵ(2)\n",
      "B CLIP Zeroshot Evaluation\n",
      "In this section, we show the result of zeroshot evaluation for CLIP. We note that the models trained on\n",
      "dataset deduplicated using SemDeDup outperform the baseline model in many tasks. In Table A4 we\n",
      "list the top1 zeroshot accuracy on 24 tasks and in Table A5 we show the top1 zeroshot accuracy on 6\n",
      "datasets for out-of-distribution robustness evaluation. Our complete evaluation set has 30different\n",
      "datasets in total. When using only 63% of LAION-440M, SemDeDup outperforms the baseline\n",
      "model in 19 out of the 30 tasks. Fig. (A4) and Fig. (A5) show the performance of different models as\n",
      "a function of training dataset size.\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "# Perform similarity search and retrieve the context from our documents\n",
    "docs = vector_db.similarity_search(query, k=1)\n",
    "# join all context information (top 4) into one string \n",
    "# context = \"\\n\".join([document.page_content for document in docs])\n",
    "context = docs[0].page_content\n",
    "print(f\"Retrieving information related to your question...\")\n",
    "print(f\"Found this content which is most similar to your question: {context}\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add context to GPT4all-j \n",
    "Adding context to large language models involves incorporating additional information or text snippets into the model’s input to enhance its understanding and generate more contextually relevant responses.  \n",
    "\n",
    "In our case, the context was retrieved using the similarity search by returning the dialogs that are closest to the question the user has asked. These dialogs are then fed to the LLM alongside the original questions in order to generate the final answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing the information with gpt4all...\n",
      "\n",
      "1. We have a large data set, LAION-440M in this case. The goal is to find duplicate records within it.\n",
      "2. To do that we need to cluster similar items together and then look for duplicates across all the clusters. This can be done using k-means clustering algorithm where each item belongs to a specific number of clusters based on its similarity with other items in the dataset. The more similar an item is, the higher it will belong to that particular cluster.\n",
      "3. Once we have clustered our data set into different groups or \"clusters\", we can then look for duplicate records within those clusters using another algorithm called SemDeDup which searches for duplicates across all items in a dataset and not just one record at a time as done by the k-means clustering algorithm.\n",
      "4. The output of this process is a list of all the duplicate records found, along with their corresponding cluster IDs or indices where they were first detected within that particular group/cluster. This information can be used to identify and remove duplicates from our dataset as needed for further analysis.1. We have a large data set, LAION-440M in this case. The goal is to find duplicate records within it.\n",
      "2. To do that we need to cluster similar items together and then look for duplicates across all the clusters. This can be done using k-means clustering algorithm where each item belongs to a specific number of clusters based on its similarity with other items in the dataset. The more similar an item is, the higher it will belong to that particular cluster.\n",
      "3. Once we have clustered our data set into different groups or \"clusters\", we can then look for duplicate records within those clusters using another algorithm called SemDeDup which searches for duplicates across all items in a dataset and not just one record at a time as done by the k-means clustering algorithm.\n",
      "4. The output of this process is a list of all the duplicate records found, along with their corresponding cluster IDs or indices where they were first detected within that particular group/cluster. This information can be used to identify and remove duplicates from our dataset as needed for further analysis.\n"
     ]
    }
   ],
   "source": [
    "# This template allows us to define the structure of the input provided to our LLM\n",
    "template = \"\"\"\n",
    "Please use the following information to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "Context: {context}\n",
    "---\n",
    "Question: {question}\n",
    "Answer: Let's think step by step.\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=['context', 'question']).partial(context=context)\n",
    "\n",
    "llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "print(\"Processing the information with gpt4all...\\n\")\n",
    "print(llm_chain.run(\"What is the SemDeDup algorithm?\"))\n",
    "# print the result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The template variable stores a pre-defined structure for the conversation, which includes a placeholder for the context and question. It also establishes a default format for the answer. By creating a PromptTemplate object, we can specify the template and the variables used within it, such as the context and question.\n",
    "\n",
    "To populate the template with the actual context value, we utilize the partial method, which replaces the {context} placeholder and generates a template string. We then create an LLMChain object that connects the partial template with the LLM model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API References\n",
    "\n",
    "* [Langchain](https://python.langchain.com/docs/get_started/introduction.html)  \n",
    "* [GPT4ALL](https://gpt4all.io/index.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
