{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG using llama2 with Ollama API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "import warnings\n",
    "import sys\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "sys.path.append('/Users/adebayoakinlalu/code_projects/pythonProjects/Generate_AI/llms') # replace with the actual path to llms directory\n",
    "\n",
    "from llms import get_ollama, create_prompt, get_answer\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = get_ollama()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context=\"\"\"Our co-founders, Andrew Bloye and David Johnson, started ClearXP in 2013 because they felt existing learning technologies\n",
    "    were too restrictive. We built a flexible and powerful digital learning platform, making learning easier for users and \n",
    "    learning administration easier for organisations. Today, our award-winning  platform is helping  hundreds of thousands of learners experience better online learning. As the world changes around us, \n",
    "    our ethos of powerful, flexible, better technology ensures all needs will continue to be met. We are succeeding in making it easier for L&D Departments to make a difference. We were particularly proud in 2020 when the ClearXP and Coles Learning Hub were awarded winner of a highly sought after AITD Excellence Award.\n",
    "    In the category of Best Use of Learning Technology, the judges were particularly impressed with our systems ability \n",
    "    to radically update and integrate learning into the culture of a large national organisation.\n",
    "\n",
    "    ClearXp products include a powerful learning management system (LMS), learning experience platform (LXP), and a learning eco-system. \n",
    "    ClearXp provides Cohesive Learner Journey to design a user centric and seamless experience encompassing all forms of digital activities, \n",
    "    face to face workshops, video conferencing and professional development. It provides Automated Support that cleverly use data and AI provides \n",
    "    a better flow for learners and makes administration and moderation a breeze for support teams. It provides Relevant and Current Content that uses\n",
    "    content authoring and visual workflows to allow teams to build user centric experiences and keep them up to date instantly. Lastly, it provides\n",
    "    Actionable Data Insights which is a powerful reporting tool on the market captures more learning touchpoints and \n",
    "    delivers real insight into what actions can be taken to improve performance and drive higher achievement.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Prompt and Chain it to the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "[INST]<<SYS>> You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.<</SYS>> \n",
    "Question: {question} \n",
    "Context: {context} \n",
    "Answer: [/INST]\n",
    "\"\"\"\n",
    "\n",
    "prompt = create_prompt(template, context)\n",
    "\n",
    "llm_chain = LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Model\n",
    "\n",
    "#### Test 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"when was ClearXP founded?\"\n",
    "get_answer(llm_chain, question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What are ClearxP products?\"\n",
    "get_answer(llm_chain, question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What is the purpose of Cohesive Learner Journey?\"\n",
    "get_answer(llm_chain, question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
