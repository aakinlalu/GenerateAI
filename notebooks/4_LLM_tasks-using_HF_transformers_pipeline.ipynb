{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM Tasks with Huggingface Transformers Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adebayoakinlalu/.pyenv/versions/3.10.12/envs/llm-env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Conversational\n",
    "Conversational response modelling is the task of generating conversational text that is relevant, coherent and knowledgable given a prompt. These models have applications in chatbots, and as a part of voice assistants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to microsoft/DialoGPT-medium and revision 8bada3b (https://huggingface.co/microsoft/DialoGPT-medium).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Downloading (…)lve/main/config.json: 100%|██████████| 642/642 [00:00<00:00, 2.52MB/s]\n",
      "Downloading pytorch_model.bin: 100%|██████████| 863M/863M [02:22<00:00, 6.07MB/s] \n",
      "Downloading (…)neration_config.json: 100%|██████████| 124/124 [00:00<00:00, 422kB/s]\n",
      "Downloading (…)okenizer_config.json: 100%|██████████| 26.0/26.0 [00:00<00:00, 128kB/s]\n",
      "Downloading (…)olve/main/vocab.json: 100%|██████████| 1.04M/1.04M [00:00<00:00, 1.29MB/s]\n",
      "Downloading (…)olve/main/merges.txt: 100%|██████████| 456k/456k [00:00<00:00, 969kB/s]\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Conversation id: 8c5e3aba-a4b4-41c5-988d-24045b444c27 \n",
       " user >> Going to the movies tonight - any suggestions? \n",
       " bot >> The Big Lebowski ,\n",
       " Conversation id: ebde4284-7a61-4d07-b939-cae90e5c9e5a \n",
       " user >> What's the last book you have read? \n",
       " bot >> The Last Question ]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Conversation \n",
    "\n",
    "converse = pipeline(\"conversational\")\n",
    "\n",
    "# Let's have a conversation\n",
    "conservation_1= Conversation(\"Going to the movies tonight - any suggestions?\")\n",
    "conversation_2 = Conversation(\"What's the last book you have read?\")\n",
    "converse([conservation_1, conversation_2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Fill-Mask\n",
    "Masked language modeling is the task of masking some of the words in a sentence and predicting which words should replace those masks. These models are useful when we want to get a statistical understanding of the language in which the model is trained in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilroberta-base and revision ec58a5b (https://huggingface.co/distilroberta-base).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Some weights of the model checkpoint at distilroberta-base were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'score': 0.48739415407180786,\n",
       "  'token': 812,\n",
       "  'token_str': ' capital',\n",
       "  'sequence': 'Paris is the capital of France'},\n",
       " {'score': 0.06109646335244179,\n",
       "  'token': 1144,\n",
       "  'token_str': ' heart',\n",
       "  'sequence': 'Paris is the heart of France'},\n",
       " {'score': 0.05793645232915878,\n",
       "  'token': 1867,\n",
       "  'token_str': ' Capital',\n",
       "  'sequence': 'Paris is the Capital of France'},\n",
       " {'score': 0.0470590777695179,\n",
       "  'token': 32357,\n",
       "  'token_str': ' birthplace',\n",
       "  'sequence': 'Paris is the birthplace of France'},\n",
       " {'score': 0.04390862211585045,\n",
       "  'token': 29778,\n",
       "  'token_str': ' envy',\n",
       "  'sequence': 'Paris is the envy of France'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier =pipeline(\"fill-mask\")\n",
    "classifier(\"Paris is the <mask> of France\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Question Answering\n",
    "Question Answering models can retrieve the answer to a question from a given text, which is useful for searching for an answer in a document. Some question answering models can generate answers without context!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Downloading (…)lve/main/config.json: 100%|██████████| 473/473 [00:00<00:00, 2.26MB/s]\n",
      "Downloading model.safetensors: 100%|██████████| 261M/261M [00:46<00:00, 5.66MB/s] \n",
      "Downloading (…)okenizer_config.json: 100%|██████████| 29.0/29.0 [00:00<00:00, 101kB/s]\n",
      "Downloading (…)solve/main/vocab.txt: 100%|██████████| 213k/213k [00:00<00:00, 590kB/s]\n",
      "Downloading (…)/main/tokenizer.json: 100%|██████████| 436k/436k [00:00<00:00, 577kB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score': 0.9793685674667358, 'start': 30, 'end': 36, 'answer': 'London'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_model = pipeline(\"question-answering\")\n",
    "\n",
    "question = \"where do I live?\"\n",
    "context = \"My name is John and I live in London\"\n",
    "qa_model(question=question, context=context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Sentence Similarity\n",
    "Sentence Similarity is the task of determining how similar two texts are. Sentence similarity models convert input texts into vectors (embeddings) that capture semantic information and calculate how close (similar) they are between them. This task is particularly useful for information retrieval and clustering/grouping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5912]])\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "sentences = [\"I'm happy\", \"I'm full of joy\"]\n",
    "\n",
    "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "embedding_1 = model.encode(sentences[0], convert_to_tensor=True)\n",
    "embedding_2 = model.encode(sentences[1], convert_to_tensor=True)\n",
    "\n",
    "cosine_scores = util.pytorch_cos_sim(embedding_1, embedding_2)\n",
    "print(cosine_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Summarization\n",
    " is the task of producing a shorter version of a document while preserving its important information. Some models can extract text from the original input, while other models can generate entirely new text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Downloading (…)lve/main/config.json: 100%|██████████| 1.80k/1.80k [00:00<00:00, 12.4MB/s]\n",
      "Downloading pytorch_model.bin: 100%|██████████| 1.22G/1.22G [04:30<00:00, 4.51MB/s]\n",
      "Downloading (…)okenizer_config.json: 100%|██████████| 26.0/26.0 [00:00<00:00, 113kB/s]\n",
      "Downloading (…)olve/main/vocab.json: 100%|██████████| 899k/899k [00:00<00:00, 1.23MB/s]\n",
      "Downloading (…)olve/main/merges.txt: 100%|██████████| 456k/456k [00:00<00:00, 537kB/s]\n",
      "Your max_length is set to 142, but your input_length is only 96. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=48)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'summary_text': ' Paris is the capital and most populous city of France, with an estimated population of 2,175,601 residents as of 2018 . The city is the centre and seat of government of the region and province of Île-de-France, or Paris Region . Paris Region has an estimated 18 percent of the population of France as of 2017 .'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = pipeline(\"summarization\")\n",
    "\n",
    "classifier(\"Paris is the capital and most populous city of France, with an estimated population of 2,175,601 residents as of 2018, in an area of more than 105 square kilometres (41 square miles). The City of Paris is the centre and seat of government of the region and province of Île-de-France, or Paris Region, which has an estimated population of 12,174,880, or about 18 percent of the population of France as of 2017.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Table Question Answering\n",
    " (Table QA) is the answering a question about an information on a given table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "data = {\"Actors\": [\"Tom Cruise\", \"Tom Hanks\", \"Brad Pitt\", \"Angelina Jolie\", \"Julia Roberts\"], \"Number of movies\": [42, 47, 53, 46, 44]}\n",
    "df = pd.DataFrame.from_dict(data)\n",
    "question = \"how many movies does Brad Pitt have?\"\n",
    "\n",
    "tga = pipeline(\"table-question-answering\", model=\"google/tapas-large-finetuned-wtq\")\n",
    "\n",
    "tga(query=question, table=df)['cells'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)lve/main/config.json: 100%|██████████| 688/688 [00:00<00:00, 1.76MB/s]\n",
      "Downloading model.safetensors: 100%|██████████| 1.43G/1.43G [04:33<00:00, 5.22MB/s]\n",
      "Some weights of the model checkpoint at roberta-large-mnli were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Downloading (…)olve/main/vocab.json: 100%|██████████| 899k/899k [00:01<00:00, 845kB/s]\n",
      "Downloading (…)olve/main/merges.txt: 100%|██████████| 456k/456k [00:00<00:00, 1.48MB/s]\n",
      "Downloading (…)/main/tokenizer.json: 100%|██████████| 1.36M/1.36M [00:00<00:00, 1.78MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'ENTAILMENT', 'score': 0.9883742332458496}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = pipeline(\"text-classification\", model = \"roberta-large-mnli\")\n",
    "classifier(\"A soccer game with multiple males playing. Some men are playing a sport.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Text Generation\n",
    "Generating text is the task of producing new text. These models can, for example, fill in incomplete text or paraphrase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading model.safetensors: 100%|██████████| 548M/548M [01:50<00:00, 4.97MB/s] \n",
      "Downloading (…)neration_config.json: 100%|██████████| 124/124 [00:00<00:00, 510kB/s]\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'Hello, I\\'m a language modeler. If I do this post, a blog post… and an interview, everyone\\'s gonna win!\"\\n\\n'},\n",
       " {'generated_text': \"Hello, I'm a language model that is really good at capturing an important insight or a key concept and using that. I've done a couple things\"},\n",
       " {'generated_text': \"Hello, I'm a language model. It took the trouble to get my PhD. It's the same thing as every other work, but my colleagues\"}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator = pipeline('text-generation', model = 'gpt2')\n",
    "generator(\"Hello, I'm a language model\", max_length = 30, num_return_sequences=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Text-to-Text generation\n",
    "Text-to-Text generation models have a separate pipeline called text2text-generation. This pipeline takes an input containing the sentence including the task and returns the output of the accomplished task.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to t5-base and revision 686f1db (https://huggingface.co/t5-base).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Downloading (…)lve/main/config.json: 100%|██████████| 1.21k/1.21k [00:00<00:00, 6.91MB/s]\n",
      "Downloading model.safetensors: 100%|██████████| 892M/892M [02:58<00:00, 5.00MB/s] \n",
      "Downloading (…)neration_config.json: 100%|██████████| 147/147 [00:00<00:00, 666kB/s]\n",
      "Downloading (…)ve/main/spiece.model: 100%|██████████| 792k/792k [00:00<00:00, 899kB/s]\n",
      "Downloading (…)/main/tokenizer.json: 100%|██████████| 1.39M/1.39M [00:00<00:00, 1.71MB/s]\n",
      "/Users/adebayoakinlalu/.pyenv/versions/3.10.12/envs/llm-env/lib/python3.10/site-packages/transformers/models/t5/tokenization_t5_fast.py:155: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'the answer to life, the universe and everything'}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2text_generator = pipeline(\"text2text-generation\")\n",
    "text2text_generator(\"question: What is 42 ? context: 42 is the answer to life, the universe and everything\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Token classification \n",
    "Token classification is a natural language understanding task in which a label is assigned to some tokens in a text. Some popular token classification subtasks are Named Entity Recognition (NER) and Part-of-Speech (PoS) tagging. NER models could be trained to identify specific entities in a text, such as dates, individuals and places; and PoS tagging would identify, for example, which words in a text are verbs, nouns, and punctuation marks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision f2482bf (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Downloading (…)lve/main/config.json: 100%|██████████| 998/998 [00:00<00:00, 4.80MB/s]\n",
      "Downloading pytorch_model.bin: 100%|██████████| 1.33G/1.33G [04:49<00:00, 4.61MB/s]\n",
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Downloading (…)okenizer_config.json: 100%|██████████| 60.0/60.0 [00:00<00:00, 172kB/s]\n",
      "Downloading (…)solve/main/vocab.txt: 100%|██████████| 213k/213k [00:00<00:00, 410kB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'entity': 'I-PER',\n",
       "  'score': 0.99770516,\n",
       "  'index': 5,\n",
       "  'word': 'Omar',\n",
       "  'start': 10,\n",
       "  'end': 14},\n",
       " {'entity': 'I-LOC',\n",
       "  'score': 0.9968976,\n",
       "  'index': 10,\n",
       "  'word': 'Zürich',\n",
       "  'start': 29,\n",
       "  'end': 35}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = pipeline(\"ner\")\n",
    "classifier(\"Hello I'm Omar and I live in Zürich.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Translation\n",
    " is the task of converting text from one language to another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)lve/main/config.json: 100%|██████████| 1.42k/1.42k [00:00<00:00, 5.85MB/s]\n",
      "Downloading pytorch_model.bin: 100%|██████████| 301M/301M [01:09<00:00, 4.36MB/s] \n",
      "Downloading (…)neration_config.json: 100%|██████████| 293/293 [00:00<00:00, 123kB/s]\n",
      "Downloading (…)okenizer_config.json: 100%|██████████| 42.0/42.0 [00:00<00:00, 49.9kB/s]\n",
      "Downloading (…)olve/main/source.spm: 100%|██████████| 778k/778k [00:00<00:00, 917kB/s]\n",
      "Downloading (…)olve/main/target.spm: 100%|██████████| 802k/802k [00:00<00:00, 1.56MB/s]\n",
      "Downloading (…)olve/main/vocab.json: 100%|██████████| 1.34M/1.34M [00:01<00:00, 1.26MB/s]\n",
      "/Users/adebayoakinlalu/.pyenv/versions/3.10.12/envs/llm-env/lib/python3.10/site-packages/transformers/models/marian/tokenization_marian.py:194: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'translation_text': 'Comment allez-vous ?'}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_checkpoint = \"Helsinki-NLP/opus-mt-en-fr\"\n",
    "translator = pipeline(\"translation\", model=model_checkpoint)\n",
    "translator(\"How are you?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Zero-shot text classification\n",
    "Zero-shot text classification is a task in natural language processing where a model is trained on a set of labeled examples but is then able to classify new examples from previously unseen classes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)lve/main/config.json: 100%|██████████| 1.15k/1.15k [00:00<00:00, 4.06MB/s]\n",
      "Downloading model.safetensors: 100%|██████████| 1.63G/1.63G [05:43<00:00, 4.75MB/s]\n",
      "Downloading (…)okenizer_config.json: 100%|██████████| 26.0/26.0 [00:00<00:00, 19.3kB/s]\n",
      "Downloading (…)olve/main/vocab.json: 100%|██████████| 899k/899k [00:00<00:00, 1.11MB/s]\n",
      "Downloading (…)olve/main/merges.txt: 100%|██████████| 456k/456k [00:00<00:00, 704kB/s]\n",
      "Downloading (…)/main/tokenizer.json: 100%|██████████| 1.36M/1.36M [00:00<00:00, 4.25MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'sequence': 'I have a problem with my iphone that needs to be resolved asap!',\n",
       " 'labels': ['urgent', 'phone', 'computer', 'not urgent', 'tablet'],\n",
       " 'scores': [0.5227586627006531,\n",
       "  0.4581395089626312,\n",
       "  0.014264822006225586,\n",
       "  0.0026850018184632063,\n",
       "  0.002152073197066784]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = pipeline(model=\"facebook/bart-large-mnli\")\n",
    "pipe(\"I have a problem with my iphone that needs to be resolved asap!\",\n",
    "    candidate_labels=[\"urgent\", \"not urgent\", \"phone\", \"tablet\", \"computer\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Depth estimation\n",
    "Depth estimation is the task of predicting depth of the objects present in an image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = pipeline(task=\"depth-estimation\", model=\"Intel/dpt-large\")\n",
    "result = estimator(images=\"http://images.cocodataset.org/val2017/000000039769.jpg\")\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13. Image classification\n",
    "Image classification is the task of assigning a label or class to an entire image. Images are expected to have only one class for each image. Image classification models take an image as input and return a prediction about which class the image belongs to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to google/vit-base-patch16-224 and revision 5dca96d (https://huggingface.co/google/vit-base-patch16-224).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Downloading (…)lve/main/config.json: 100%|██████████| 69.7k/69.7k [00:00<00:00, 338kB/s]\n",
      "Downloading pytorch_model.bin: 100%|██████████| 346M/346M [00:52<00:00, 6.56MB/s] \n",
      "Downloading (…)rocessor_config.json: 100%|██████████| 160/160 [00:00<00:00, 656kB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'score': 0.8808925151824951, 'label': 'golden retriever'},\n",
       " {'score': 0.0977909192442894, 'label': 'Labrador retriever'},\n",
       " {'score': 0.0021747981663793325, 'label': 'tennis ball'},\n",
       " {'score': 0.0019781359005719423, 'label': 'Sussex spaniel'},\n",
       " {'score': 0.001014324021525681, 'label': 'kuvasz'}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = pipeline(\"image-classification\")\n",
    "clf(\"images/dog-puppy-on-garden-royalty-free-image-1586966191.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14. Image Segmentation\n",
    "Image Segmentation divides an image into segments where each pixel in the image is mapped to an object. This task has multiple variants such as instance segmentation, panoptic segmentation and semantic segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to facebook/detr-resnet-50-panoptic and revision fc15262 (https://huggingface.co/facebook/detr-resnet-50-panoptic).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Downloading model.safetensors: 100%|██████████| 102M/102M [00:15<00:00, 6.53MB/s] \n",
      "Some weights of the model checkpoint at facebook/detr-resnet-50-panoptic were not used when initializing DetrForSegmentation: ['detr.model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked', 'detr.model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'detr.model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'detr.model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked']\n",
      "- This IS expected if you are initializing DetrForSegmentation from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DetrForSegmentation from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Downloading (…)rocessor_config.json: 100%|██████████| 273/273 [00:00<00:00, 1.38MB/s]\n",
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n",
      "The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n",
      "`label_ids_to_fuse` unset. No instance will be fused.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'score': 0.99892,\n",
       "  'label': 'LABEL_193',\n",
       "  'mask': <PIL.Image.Image image mode=L size=1200x1197>},\n",
       " {'score': 0.998526,\n",
       "  'label': 'dog',\n",
       "  'mask': <PIL.Image.Image image mode=L size=1200x1197>}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = pipeline(\"image-segmentation\")\n",
    "model(\"images/dog-puppy-on-garden-royalty-free-image-1586966191.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15. Image-to-image\n",
    "Image-to-image is the task of transforming a source image to match the characteristics of a target image or a target image domain. Any image manipulation and enhancement is possible with image to image models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "from diffusers import StableDiffusionImg2ImgPipeline\n",
    "model_id_or_path = \"runwayml/stable-diffusion-v1-5\"\n",
    "pipe = StableDiffusionImg2ImgPipeline.from_pretrained(model_id_or_path, torch_dtype=torch.float16)\n",
    "pipe = pipe.to(\"cuda\")\n",
    "\n",
    "init_image = Image.open(\"images/dog-puppy-on-garden-royalty-free-image-1586966191.jpg\").convert(\"RGB\").resize((768, 512))\n",
    "prompt = \"A running dog in the forest\"\n",
    "\n",
    "images = pipe(prompt=prompt, image=init_image, strength=0.75, guidance_scale=7.5).images\n",
    "images[0].save(\"images/running_dogs.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 16. Object Detection\n",
    "Object Detection models allow users to identify objects of certain defined classes. Object detection models receive an image as input and output the images with bounding boxes and labels on detected objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pipeline(\"object-detection\")\n",
    "\n",
    "model(\"images/dog-puppy-on-garden-royalty-free-image-1586966191.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 17. Text-to-Speech\n",
    "Text-to-Speech (TTS) is the task of generating natural sounding speech given text input. TTS models can be extended to have a single model that generates speech for multiple speakers and multiple languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from espnet2.bin.tts_inference import Text2Speech\n",
    "\n",
    "model = Text2Speech.from_pretrained(\"espnet/kan-bayashi_ljspeech_vits\")\n",
    "\n",
    "speech, *_ = model(\"Hello, I'm a language model.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 18.Feature extraction \n",
    "refers to the process of transforming raw data into numerical features that can be processed while preserving the information in the original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"facebook/bart-base\"\n",
    "feature_extractor = pipeline(\"feature-extraction\",framework=\"pt\",model=checkpoint)\n",
    "text = \"Transformers is an awesome library!\"\n",
    "\n",
    "#Reducing along the first dimension to get a 768 dimensional array\n",
    "feature_extractor(text,return_tensors = \"pt\")[0].numpy().mean(axis=0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 19. Image to text \n",
    "models output a text from a given image. Image captioning or optical character recognition can be considered as the most common applications of image to text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'a puppy sitting in the grass with its mouth open'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "captioner = pipeline(\"image-to-text\",model=\"Salesforce/blip-image-captioning-base\")\n",
    "captioner(\"images/dog-puppy-on-garden-royalty-free-image-1586966191.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20. Text to Image \n",
    "Generates images from input text. These models can be used to generate and modify images based on text prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import StableDiffusionPipeline, EulerDiscreteScheduler\n",
    "import torch\n",
    "model_id = \"stabilityai/stable-diffusion-2\"\n",
    "scheduler = EulerDiscreteScheduler.from_pretrained(model_id, subfolder=\"scheduler\")\n",
    "pipe = StableDiffusionPipeline.from_pretrained(model_id, scheduler=scheduler, torch_dtype=torch.float16)\n",
    "pipe = pipe.to(\"mps\")\n",
    "\n",
    "prompt = \"a photo of an astronaut riding a horse on mars\"\n",
    "image = pipe(prompt).images[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 21. Visual Question Answering\n",
    "Visual Question Answering is the task of answering open-ended questions based on an image. They output natural language responses to natural language questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dandelin/vilt-b32-finetuned-vqa and revision 4355f59 (https://huggingface.co/dandelin/vilt-b32-finetuned-vqa).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'score': 0.999915599822998, 'answer': 'yes'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from transformers import pipeline\n",
    "\n",
    "vqa_pipeline = pipeline(\"visual-question-answering\")\n",
    "\n",
    "image =  Image.open(\"images/dog-puppy-on-garden-royalty-free-image-1586966191.jpg\")\n",
    "question = \"Is there a dog?\"\n",
    "\n",
    "vqa_pipeline(image, question, top_k=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 22. Zero shot image classification \n",
    "Zero shot image classification is the task of classifying previously unseen classes during training of a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"openai/clip-vit-large-patch14-336\"\n",
    "classifier = pipeline(\"zero-shot-image-classification\", model = model_name)\n",
    "\n",
    "image_to_classify = \"images/dog-puppy-on-garden-royalty-free-image-1586966191.jpg\"\n",
    "labels_for_classification =  [\"dog\", \n",
    "                              \"lion\", \n",
    "                              \"rabbit\"]\n",
    "scores = classifier(image_to_classify, \n",
    "                    candidate_labels = labels_for_classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
