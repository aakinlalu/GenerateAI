{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install argilla langchain outlines tiktoken transformers ipywidgets jupyter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argilla as rg \n",
    "\n",
    "import os \n",
    "import random\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain import LLMChain \n",
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "from outlines import models\n",
    "from outlines import generate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adebayoakinlalu/.pyenv/versions/3.11.4/envs/llm-env2/lib/python3.11/site-packages/argilla/client/client.py:167: UserWarning: Default user was detected and no workspace configuration was provided, so the default 'argilla' workspace will be used. If you want to setup another workspace, use the `rg.set_workspace` function or provide a different one on `rg.init`\n",
      "  warnings.warn(\n",
      "/Users/adebayoakinlalu/.pyenv/versions/3.11.4/envs/llm-env2/lib/python3.11/site-packages/argilla/client/client.py:195: UserWarning: You're connecting to Argilla Server 1.23.0-dev4 using a different client version (1.25.0).\n",
      "This may lead to potential compatibility issues during your experience.\n",
      "To ensure a seamless and optimized connection, we highly recommend aligning your client version with the server version.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "rg.init(\n",
    "    api_url=\"http://localhost:6900\",\n",
    "    api_key=\"argilla.apikey\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a FeedbackDataset\n",
    " this example, we will create a synthetic dataset for a banking customer care scenario. We assume that customers will write text requests. These requests should then be classified for sentiment and topics. The topics will be a multi-label classification and can be used to route the request to the correct department. The sentiment will be used using a single-label classification to determine if the request needs to be handled with priority."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = ['positive', 'negative', 'neutral']\n",
    "topic = ['new_card', 'mortgage', \"application\", \"payments\"]\n",
    "\n",
    "dataset = rg.FeedbackDataset(\n",
    "    fields = [rg.TextField(name=\"text\")],\n",
    "    questions = [\n",
    "        rg.LabelQuestion(\n",
    "            name=\"sentiment\",\n",
    "            title = \"what is the sentiment of the message?\",\n",
    "            labels=sentiment\n",
    "        ),\n",
    "        rg.MultiLabelQuestion(\n",
    "            name=\"topics\",\n",
    "            title=\"Select the topic(s) of the messages?\",\n",
    "            labels=topic,\n",
    "            visible_labels=4,\n",
    "        )\n",
    "    ],\n",
    "    guidelines=(\n",
    "        \"This dataset contains messages from a banks customer support chatbot. \"\n",
    "        \"The goal is to label the sentiment of the message and the topic of the message. \"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "config.json: 100%|██████████| 596/596 [00:00<00:00, 1.17MB/s]\n",
      "model.safetensors.index.json: 100%|██████████| 25.1k/25.1k [00:00<00:00, 37.7MB/s]\n",
      "model-00001-of-00003.safetensors: 100%|██████████| 4.94G/4.94G [12:46<00:00, 6.45MB/s]\n",
      "model-00002-of-00003.safetensors: 100%|██████████| 5.00G/5.00G [13:14<00:00, 6.30MB/s]\n",
      "model-00003-of-00003.safetensors: 100%|██████████| 4.54G/4.54G [11:50<00:00, 6.39MB/s]\n",
      "Downloading shards: 100%|██████████| 3/3 [37:54<00:00, 758.04s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:49<00:00, 16.39s/it]\n",
      "generation_config.json: 100%|██████████| 111/111 [00:00<00:00, 776kB/s]\n",
      "tokenizer_config.json: 100%|██████████| 1.46k/1.46k [00:00<00:00, 5.51MB/s]\n",
      "tokenizer.model: 100%|██████████| 493k/493k [00:00<00:00, 1.75MB/s]\n",
      "tokenizer.json: 100%|██████████| 1.80M/1.80M [00:01<00:00, 1.59MB/s]\n",
      "special_tokens_map.json: 100%|██████████| 72.0/72.0 [00:00<00:00, 486kB/s]\n"
     ]
    }
   ],
   "source": [
    "mistral_model = models.transformers(\"mistralai/Mistral-7B-Instruct-v0.2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = generate.text(mistral_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "\n",
    "llm = Ollama(\n",
    "    model=\"mistral\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I recently applied for a loan at XYZ Bank and had a positive experience overall. The staff was friendly and knowledgeable, and they provided me with all the information I needed to make an informed decision about my loan. However, the process was quite lengthy and there were a few minor delays along the way. Despite this, I am satisfied with the outcome of my application and would recommend XYZ Bank to others who are looking for a reliable and efficient banking experience. Overall, it was a good experience!'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = (\n",
    "    \"Write a customer review for a bank. \"\n",
    "    \"Do that for topic of {topic}. \"\n",
    "    \"Do that with one a {sentiment} sentiment.\"\n",
    ")\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"topic\", \"sentiment\"])\n",
    "llm_chain_review = LLMChain(prompt=prompt, llm=llm)\n",
    "\n",
    "def generate_langchain_review():\n",
    "    return llm_chain_review.predict(\n",
    "        topic=random.choice(topic),\n",
    "        sentiment=random.choice(sentiment)\n",
    "    ).strip()\n",
    "\n",
    "generate_langchain_review()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Title: Neutral Review of Bank's Mortgage Services\\n\\nOverall, I had a neutral experience with the bank's mortgage services. The process was straightforward and efficient, with clear communication throughout the entire process. The staff were friendly and helpful, but it took some time for me to receive my final documents. However, I am happy with the interest rate and payment plan that I was able to secure. Overall, I would recommend the bank's mortgage services to others who are looking for a reliable and efficient mortgage experience.\",\n",
       " '\"I recently applied for a new account at XYZ Bank and I was very pleased with the experience. The online application process was easy to navigate, and I appreciated the clear instructions provided throughout. The customer service team was also very helpful and responsive, answering all of my questions promptly. Overall, I had a positive experience and would recommend XYZ Bank to anyone in need of a reliable banking solution.\"']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_n_langchain_reviews(n=2):\n",
    "    reviews = []\n",
    "    for n in range(n):\n",
    "        reviews.append(generate_langchain_review())\n",
    "    return reviews\n",
    "\n",
    "langchain_reviews = generate_n_langchain_reviews()\n",
    "langchain_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_n_langchain_reviews(n=5):\n",
    "    reviews = []\n",
    "    for n in range(n):\n",
    "        reviews.append(generate_langchain_review())\n",
    "    return reviews\n",
    "\n",
    "langchain_reviews = generate_n_langchain_reviews(5)\n",
    "langchain_reviews"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
